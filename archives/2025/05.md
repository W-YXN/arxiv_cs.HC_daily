# May 2025 Archive

[Back to README](../../README.md)

|date|paper|code|
|---|---|---|
|2505.02060|[transforming faces into video stories -- videoface2.0](https://arxiv.org/abs/2505.02060)|[videoface2.0](https://github.com/brkljac/videoface2.0)|
|2505.02393|[uncertainty-weighted image-event multimodal fusion for video anomaly detection](https://arxiv.org/abs/2505.02393)|[ief-vad](https://github.com/eavnjeong/ief-vad)|
|2505.03856|[an active inference model of covert and overt visual attention](https://arxiv.org/abs/2505.03856)|[ainf-visual-attention](https://github.com/unizgfer-lamor/ainf-visual-attention)|
|2505.04281|[ts-diff: two-stage diffusion model for low-light raw image enhancement](https://arxiv.org/abs/2505.04281)|[ts-diff](https://github.com/circcclek/ts-diff)|
|2505.04586|[active sampling for mri-based sequential decision making](https://arxiv.org/abs/2505.04586)|[mri_sequential_active_sampling](https://github.com/vios-s/mri_sequential_active_sampling)|
|2505.04590|[tetweave: isosurface extraction using on-the-fly delaunay tetrahedral grids for gradient-based mesh optimization](https://arxiv.org/abs/2505.04590)|[TetWeave](https://github.com/AlexandreBinninger/TetWeave)|
|2505.04652|[rethinking boundary detection in deep learning-based medical image segmentation](https://arxiv.org/abs/2505.04652)|[cto](https://github.com/xiaofang007/cto)|
|2505.04835|[are synthetic corruptions a reliable proxy for real-world corruptions?](https://arxiv.org/abs/2505.04835)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|
|2505.05001|[stabstitch++: unsupervised online video stitching with spatiotemporal bidirectional warps](https://arxiv.org/abs/2505.05001)|[stabstitch2](https://github.com/nie-lang/stabstitch2)|
|2505.05007|[driving with context: online map matching for complex roads using lane markings and scenario recognition](https://arxiv.org/abs/2505.05007)|[lmsr-omm](https://github.com/trv-lab/lmsr-omm)|
|2505.05022|[soap: style-omniscient animatable portraits](https://arxiv.org/abs/2505.05022)|[soap](https://github.com/tingtingliao/soap)|
|2505.05091|[dispbench: benchmarking disparity estimation to synthetic corruptions](https://arxiv.org/abs/2505.05091)|[benchmarking_robustness](https://github.com/shashankskagnihotri/benchmarking_robustness)|
|2505.05309|[augmented deep contexts for spatially embedded video coding](https://arxiv.org/abs/2505.05309)|[sevc](https://github.com/esakak/sevc)|
|2505.05343|[hearing and seeing through clip: a framework for self-supervised sound source localization](https://arxiv.org/abs/2505.05343)|[ACL-SSL](https://github.com/swimmiing/ACL-SSL)|
|2505.05469|[generating physically stable and buildable lego designs from text](https://arxiv.org/abs/2505.05469)|[LegoGPT](https://github.com/AvaLovelace1/LegoGPT)|
|2505.05470|[flow-grpo: training flow matching models via online rl](https://arxiv.org/abs/2505.05470)|[flow_grpo](https://github.com/yifan123/flow_grpo)|
|2505.05474|[3d scene generation: a survey](https://arxiv.org/abs/2505.05474)|[awesome-3d-scene-generation](https://github.com/hzxie/awesome-3d-scene-generation)|
|2505.05475|[svad: from single image to 3d avatar via synthetic data generation with video diffusion and data augmentation](https://arxiv.org/abs/2505.05475)|[SVAD](https://github.com/yc4ny/SVAD)|
|2505.02406|[token coordinated prompt attention is needed for visual prompting](https://arxiv.org/abs/2505.02406)|[icml2025-tcpa](https://github.com/zhoujiahuan1991/icml2025-tcpa)|
|2505.02471|[ming-lite-uni: advancements in unified architecture for natural multimodal interaction](https://arxiv.org/abs/2505.02471)|[ming](https://github.com/inclusionai/ming)|
|2505.02567|[unified multimodal understanding and generation models: advances, challenges, and opportunities](https://arxiv.org/abs/2505.02567)|[awesome-unified-multimodal-models](https://github.com/aidc-ai/awesome-unified-multimodal-models)|
|2505.03836|[obd-finder: explainable coarse-to-fine text-centric oracle bone duplicates discovery](https://arxiv.org/abs/2505.03836)|[obd-finder](https://github.com/cszhanglmu/obd-finder)|
|2505.03896|[novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation](https://arxiv.org/abs/2505.03896)|[attukan](https://github.com/stevezs315/attukan)|
|2505.04003|[prototype-based information compensation network for multi-source remote sensing data classification](https://arxiv.org/abs/2505.04003)|[picnet](https://github.com/oucailab/picnet)|
|2505.04119|[gaprompt: geometry-aware point cloud prompt for 3d vision model](https://arxiv.org/abs/2505.04119)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|
|2505.04121|[vision graph prompting via semantic low-rank decomposition](https://arxiv.org/abs/2505.04121)|[icml2025-vgp](https://github.com/zhoujiahuan1991/icml2025-vgp)|
|2505.04185|[s3d: sketch-driven 3d model generation](https://arxiv.org/abs/2505.04185)|[s3d](https://github.com/hailsong/s3d)|
|2505.04192|[videopath-llava: pathology diagnostic reasoning through video instruction tuning](https://arxiv.org/abs/2505.04192)|[videopath-llava](https://github.com/trinhvg/videopath-llava)|
|2505.04276|[hdifftg: a lightweight hybrid diffusion-transformer-gcn architecture for 3d human pose estimation](https://arxiv.org/abs/2505.04276)|[hdifftg](https://github.com/circejie/hdifftg)|
|2505.04369|[wdmamba: when wavelet degradation prior meets vision mamba for image dehazing](https://arxiv.org/abs/2505.04369)|[wdmamba](https://github.com/sunj000/wdmamba)|
|2505.04410|[declip: decoupled learning for open-vocabulary dense perception](https://arxiv.org/abs/2505.04410)|[declip](https://github.com/xiaomoguhz/declip)|
|2505.04526|[dfvo: learning darkness-free visible and infrared image disentanglement and fusion all at once](https://arxiv.org/abs/2505.04526)|[dfvo](https://github.com/davin-qi530/dfvo)|
|2505.04540|[registration of 3d point sets using exponential-based similarity matrix](https://arxiv.org/abs/2505.04540)|[esm_icp](https://github.com/aralab-unr/esm_icp)|
|2505.04575|[componential prompt-knowledge alignment for domain incremental learning](https://arxiv.org/abs/2505.04575)|[icml2025-ka-prompt](https://github.com/zhoujiahuan1991/icml2025-ka-prompt)|
|2505.04623|[echoink-r1: exploring audio-visual reasoning in multimodal llms via reinforcement learning](https://arxiv.org/abs/2505.04623)|[echoink](https://github.com/harryhsing/echoink)|
|2505.01884|[adversarial robustness of deep learning models for inland water body segmentation from sar images](https://arxiv.org/abs/2505.01884)|[iwseg-sar-poison](https://github.com/gvcl/iwseg-sar-poison)|
|2505.02048|[regression is all you need for medical image translation](https://arxiv.org/abs/2505.02048)|[yoda](https://github.com/deep-mi/yoda)|
|2505.02064|[rtv-bench: benchmarking mllm continuous perception, understanding and reasoning through real-time video](https://arxiv.org/abs/2505.02064)|[rtv-bench](https://github.com/ljungang/rtv-bench)|
|2505.02704|[vgld: visually-guided linguistic disambiguation for monocular depth scale recovery](https://arxiv.org/abs/2505.02704)|[vgld](https://github.com/pakinwu/vgld)|
|2505.02971|[adversarial robustness analysis of vision-language models in medical image segmentation](https://arxiv.org/abs/2505.02971)|[secure-private-ai](https://github.com/anjilab/secure-private-ai)|
|2505.03007|[ntire 2025 challenge on ugc video enhancement: methods and results](https://arxiv.org/abs/2505.03007)|[ntire25_ugc_video_enhancement](https://github.com/msu-video-group/ntire25_ugc_video_enhancement)|
|2505.03046|[sim2real transfer for vision-based grasp verification](https://arxiv.org/abs/2505.03046)|[hsr-graspsynth](https://github.com/pauamargant/hsr-graspsynth)|
|2505.03114|[path and bone-contour regularized unpaired mri-to-ct translation](https://arxiv.org/abs/2505.03114)|[pabot](https://github.com/kennysyp/pabot)|
|2505.03153|[robust fairness vision-language learning for medical image analysis](https://arxiv.org/abs/2505.03153)|[robust_fairness_for_medical_image](https://github.com/purdue-m2/robust_fairness_for_medical_image)|
|2505.03242|[seeing the abstract: translating the abstract language for vision language models](https://arxiv.org/abs/2505.03242)|[fashionact](https://github.com/davidetalon/fashionact)|
|2505.03299|[towards efficient benchmarking of foundation models in remote sensing: a capabilities encoding approach](https://arxiv.org/abs/2505.03299)|[capabilities-encoding](https://github.com/pierreadorni/capabilities-encoding)|
|2505.03319|[sd-vsum: a method and dataset for script-driven video summarization](https://arxiv.org/abs/2505.03319)|[sd-vsum](https://github.com/idt-iti/sd-vsum)|
|2505.03401|[ddatr: dynamic difference-aware temporal residual network for longitudinal radiology report generation](https://arxiv.org/abs/2505.03401)|[ddatr](https://github.com/xmed-lab/ddatr)|
|2505.03422|[liftfeat: 3d geometry-aware local feature matching](https://arxiv.org/abs/2505.03422)|[liftfeat](https://github.com/lyp-deeplearning/liftfeat)|
|2505.03427|[medarabiq: benchmarking large language models on arabic medical tasks](https://arxiv.org/abs/2505.03427)|[medarabiq](https://github.com/nyuad-cai/medarabiq)|
|2505.03431|[a fusion-guided inception network for hyperspectral image super-resolution](https://arxiv.org/abs/2505.03431)|[fusion](https://github.com/usman1021/fusion)|
|2505.03470|[blending 3d geometry and machine learning for multi-view stereopsis](https://arxiv.org/abs/2505.03470)|[GC-MVSNet-PlusPlus](https://github.com/vkvats/GC-MVSNet-PlusPlus)|
|2505.03480|[modeling musical genre trajectories through pathlet learning](https://arxiv.org/abs/2505.03480)|[music_pathlets](https://github.com/lilianmarey/music_pathlets)|
|2505.03494|[upmad-net: a brain tumor segmentation network with uncertainty guidance and adaptive multimodal feature fusion](https://arxiv.org/abs/2505.03494)|[upmad_net_brainseg](https://github.com/chenzhao2023/upmad_net_brainseg)|
|2505.03507|[modality-guided dynamic graph fusion and temporal diffusion for self-supervised rgb-t tracking](https://arxiv.org/abs/2505.03507)|[gdstrack](https://github.com/lishenglana/gdstrack)|
|2505.03538|[rail: region-aware instructive learning for semi-supervised tooth segmentation in cbct](https://arxiv.org/abs/2505.03538)|[rail](https://github.com/tournesol-saturday/rail)|
|2505.03539|[panoramic out-of-distribution segmentation](https://arxiv.org/abs/2505.03539)|[panoos](https://github.com/mengfeid/panoos)|
|2505.03568|[familiarizing with music: discovery patterns for different music discovery needs](https://arxiv.org/abs/2505.03568)|[familiarizing_with_music](https://github.com/hcai-mms/familiarizing_with_music)|
|2505.03581|[dygenc: encoding a sequence of textual scene graphs to reason and answer questions in dynamic scenes](https://arxiv.org/abs/2505.03581)|[dygenc](https://github.com/linukc/dygenc)|
|2505.03597|[fixed-length dense fingerprint representation](https://arxiv.org/abs/2505.03597)|[flare](https://github.com/yu-yy/flare)|
|2505.03623|[bounding box-guided diffusion for synthesizing industrial images and segmentation map](https://arxiv.org/abs/2505.03623)|[diffusion_labeling](https://github.com/covisionlab/diffusion_labeling)|
|2505.03692|[matching distance and geometric distribution aided learning multiview point cloud registration](https://arxiv.org/abs/2505.03692)|[mdgd](https://github.com/shi-qi-li/mdgd)|
|2505.00630|[vision mamba in remote sensing: a comprehensive survey of techniques, applications and outlook](https://arxiv.org/abs/2505.00630)|[awesome-mamba-in-remote-sensing](https://github.com/baobao0926/awesome-mamba-in-remote-sensing)|
|2505.01431|[zs-vcos: zero-shot outperforms supervised video camouflaged object segmentation](https://arxiv.org/abs/2505.01431)|[vcos](https://github.com/weathon/vcos)|
|2505.01456|[unlearning sensitive information in multimodal llms: benchmark and attack-defense evaluation](https://arxiv.org/abs/2505.01456)|[unlok-vqa](https://github.com/vaidehi99/unlok-vqa)|
|2505.01476|[costfilter-ad: enhancing anomaly detection through matching cost filtering](https://arxiv.org/abs/2505.01476)|[costfilter-ad](https://github.com/zhe-sapi/costfilter-ad)|
|2505.01481|[videohallu: evaluating and mitigating multi-modal hallucinations for synthetic videos](https://arxiv.org/abs/2505.01481)|[videohallu](https://github.com/zli12321/videohallu)|
|2505.01548|[rethinking rgb-event semantic segmentation with a novel bidirectional motion-enhanced event representation](https://arxiv.org/abs/2505.01548)|[BRENet](https://github.com/zyaocoder/BRENet)|
|2505.01583|[tempura: temporal event masked prediction and understanding for reasoning in action](https://arxiv.org/abs/2505.01583)|[tempura](https://github.com/andy-cheng/tempura)|
|2505.01644|[a dual-task synergy-driven generalization framework for pancreatic cancer segmentation in ct scans](https://arxiv.org/abs/2505.01644)|[dual-task-seg](https://github.com/sjtubme-qianlab/dual-task-seg)|
|2505.01699|[component-based fairness in face attribute classification with bayesian network-informed meta learning](https://arxiv.org/abs/2505.01699)|[bnmr-faircompface](https://github.com/yliuaa/bnmr-faircompface)|
|2505.01724|[vistaxa: developing a taxonomy of historical visualizations](https://arxiv.org/abs/2505.01724)|[image-taxonomy-labeler](https://github.com/oldvis/image-taxonomy-labeler)|
|2505.01755|[lensnet: an end-to-end learning framework for empirical point spread function modeling and lensless imaging reconstruction](https://arxiv.org/abs/2505.01755)|[Lensnet](https://github.com/baijiesong/Lensnet)|
|2505.01779|[polar interpolants for thin-shell microstructure homogenization](https://arxiv.org/abs/2505.01779)|[polarinterpolants](https://github.com/antoine-chan-lock/polarinterpolants)|
|2505.01790|[enhancing the learning experience: using vision-language models to generate questions for educational videos](https://arxiv.org/abs/2505.01790)|[aied_2025_video_qg](https://github.com/markossta/aied_2025_video_qg)|
|2505.01854|[accelerating volumetric medical image annotation via short-long memory sam 2](https://arxiv.org/abs/2505.01854)|[slm-sam2](https://github.com/mazurowski-lab/slm-sam2)|
|2505.01938|[hybridgs: high-efficiency gaussian splatting data compression using dual-channel sparse representation and point cloud encoder](https://arxiv.org/abs/2505.01938)|[hybridgs](https://github.com/qi-yangsjtu/hybridgs)|
|2505.02005|[learning heterogeneous mixture of scene experts for large-scale neural radiance fields](https://arxiv.org/abs/2505.02005)|[Switch-NeRF](https://github.com/MiZhenxing/Switch-NeRF)|
|2505.02075|[benchmarking feature upsampling methods for vision foundation models using interactive segmentation](https://arxiv.org/abs/2505.02075)|[isegprobe](https://github.com/havrylovv/isegprobe)|
|2505.02159|[small clips, big gains: learning long-range refocused temporal information for video super-resolution](https://arxiv.org/abs/2505.02159)|[lrti-vsr](https://github.com/labshuhanggu/lrti-vsr)|
|2505.02179|[prodisc-vad: an efficient system for weakly-supervised anomaly detection in video surveillance applications](https://arxiv.org/abs/2505.02179)|[ProDisc-VAD](https://github.com/modadundun/ProDisc-VAD)|
|2505.02182|[robust ai-generated face detection with imbalanced data](https://arxiv.org/abs/2505.02182)|[sp_cup](https://github.com/purdue-m2/sp_cup)|
|2505.02246|[cricket: a self-powered chirping pixel](https://arxiv.org/abs/2505.02246)|[cricket-public](https://github.com/columbiacomputervision/cricket-public)|
|2505.02325|[teda: boosting vision-lanuage models for zero-shot 3d object retrieval via testing-time distribution alignment](https://arxiv.org/abs/2505.02325)|[teda](https://github.com/wangzhichuan123/teda)|
|2505.02331|[vaemo: efficient representation learning for visual-audio emotion with knowledge injection](https://arxiv.org/abs/2505.02331)|[VAEmo](https://github.com/MSA-LMC/VAEmo)|
|2505.02350|[sparse ellipsoidal radial basis function network for point cloud surface representation](https://arxiv.org/abs/2505.02350)|[se-rbfnet](https://github.com/lianbobo/se-rbfnet)|
|2505.02370|[superedit: rectifying and facilitating supervision for instruction-based image editing](https://arxiv.org/abs/2505.02370)|[superedit](https://github.com/bytedance/superedit)|
|2505.02385|[an arbitrary-modal fusion network for volumetric cranial nerves tract segmentation](https://arxiv.org/abs/2505.02385)|[cntseg](https://github.com/ipis-xielei/cntseg)|
|2505.02414|[quadrupedal spine control strategies: exploring correlations between system dynamic responses and human perspectives](https://arxiv.org/abs/2505.02414)|[ester](https://github.com/nickick-icrs/ester)|
|2505.02481|[finger pose estimation for under-screen fingerprint sensor](https://arxiv.org/abs/2505.02481)|[draco](https://github.com/xiongjunguan/draco)|
|2505.02654|[sim2real in endoscopy segmentation with a novel structure aware image translation](https://arxiv.org/abs/2505.02654)|[sim2real-endoscopysegmentation](https://github.com/ropertuz/sim2real-endoscopysegmentation)|
|2505.02705|[multi-view learning with context-guided receptance for image denoising](https://arxiv.org/abs/2505.02705)|[crwkv](https://github.com/seeker98/crwkv)|
|2505.02746|[using knowledge graphs to harvest datasets for efficient clip model training](https://arxiv.org/abs/2505.02746)|[entitynet](https://github.com/lmb-freiburg/entitynet)|
|2505.02753|[advancing generalizable tumor segmentation with anomaly-aware open-vocabulary attention maps and frozen foundation diffusion models](https://arxiv.org/abs/2505.02753)|[diffugts](https://github.com/yankai96/diffugts)|
|2505.02780|[beyond the monitor: mixed reality visualization and ai for enhanced digital pathology workflow](https://arxiv.org/abs/2505.02780)|[path_vis](https://github.com/jaiprakash1824/path_vis)|
|2505.02823|[musar: exploring multi-subject customization from single-subject dataset via attention routing](https://arxiv.org/abs/2505.02823)|[musar](https://github.com/guozinan126/musar)|
|2505.02824|[towards dataset copyright evasion attack against personalized text-to-image diffusion models](https://arxiv.org/abs/2505.02824)|[ceat2i](https://github.com/csyufei/ceat2i)|
|2505.00056|[clustering internet memes through template matching and multi-dimensional similarity](https://arxiv.org/abs/2505.00056)|[meme-clustering](https://github.com/tygobl/meme-clustering)|
|2505.00568|[multimodal masked autoencoder pre-training for 3d mri-based brain tumor analysis with missing modalities](https://arxiv.org/abs/2505.00568)|[bm-mae](https://github.com/lucas-rbnt/bm-mae)|
|2505.00740|[fast2comm:collaborative perception combined with prior knowledge](https://arxiv.org/abs/2505.00740)|[fast2comm](https://github.com/zhangzhengbin-tj/fast2comm)|
|2505.00772|[person detection and re-identification in open-world settings of retail stores and public spaces](https://arxiv.org/abs/2505.00772)|[personReID](https://github.com/brkljac/personReID)|
|2505.00866|[are minimal radial distortion solvers really necessary for relative pose estimation?](https://arxiv.org/abs/2505.00866)|[rdnet](https://github.com/kocurvik/rdnet)|
|2505.00938|[cdformer: cross-domain few-shot object detection transformer against feature confusion](https://arxiv.org/abs/2505.00938)|[CDFormer_code](https://github.com/LONGXUANX/CDFormer_code)|
|2505.01172|[freepca: integrating consistency information across long-short frames in training-free long video generation via principal component analysis](https://arxiv.org/abs/2505.01172)|[freepca](https://github.com/josephtitan/freepca)|
|2505.01224|[rd-uie: relation-driven state space modeling for underwater image enhancement](https://arxiv.org/abs/2505.01224)|[rd-uie](https://github.com/kkoucy/rd-uie)|
|2505.01225|[core-set selection for data-efficient land cover segmentation](https://arxiv.org/abs/2505.01225)|[data-centric-rs-classification](https://github.com/keillernogueira/data-centric-rs-classification)|
|2505.01257|[cameltrack: context-aware multi-cue exploitation for online multi-object tracking](https://arxiv.org/abs/2505.01257)|[CAMELTrack](https://github.com/TrackingLaboratory/CAMELTrack)|
|2505.01406|[vidstamp: a temporally-aware watermark for ownership and integrity in video diffusion models](https://arxiv.org/abs/2505.01406)|[vidstamp](https://github.com/spin-umass/vidstamp)|
|2505.00312|[aware-net: adaptive weighted averaging for robust ensemble network in deepfake detection](https://arxiv.org/abs/2505.00312)|[AWARE-NET](https://github.com/recluzegeek/AWARE-NET)|
|2505.00502|[towards scalable human-aligned benchmark for text-guided image editing](https://arxiv.org/abs/2505.00502)|[HATIE](https://github.com/SuhoRyu/HATIE)|
|2505.00681|[minerva: evaluating complex video reasoning](https://arxiv.org/abs/2505.00681)|[neptune](https://github.com/google-deepmind/neptune)|
|2505.00684|[visual test-time scaling for gui agent grounding](https://arxiv.org/abs/2505.00684)|[regionfocus](https://github.com/tiangeluo/regionfocus)|
|2505.00703|[t2i-r1: reinforcing image generation with collaborative semantic-level and token-level cot](https://arxiv.org/abs/2505.00703)|[t2i-r1](https://github.com/caraj7/t2i-r1)|

